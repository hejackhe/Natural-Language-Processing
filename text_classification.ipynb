{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification for social media - He Tianyou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier part one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train_data = pd.read_csv('semeval-tweets/twitter-training-data.txt', sep='\\t', names=['tweet_id','sentiment','tweet_text'])\n",
    "# Read dev data\n",
    "dev_data = pd.read_csv('semeval-tweets/twitter-dev-data.txt', sep='\\t', names=['tweet_id','sentiment','tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335104872099066692</td>\n",
       "      <td>positive</td>\n",
       "      <td>felt privileged to play foo fighters songs on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>796528524030124618</td>\n",
       "      <td>positive</td>\n",
       "      <td>pakistan may be an islamic country, but der a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>760964834217238632</td>\n",
       "      <td>positive</td>\n",
       "      <td>happy birthday to the coolest golfer in bali! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147713180324524046</td>\n",
       "      <td>negative</td>\n",
       "      <td>tmills is going to tucson! but the 29th and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>732302280474120023</td>\n",
       "      <td>negative</td>\n",
       "      <td>hmmmmm where are the #blacklivesmatter when ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id sentiment  \\\n",
       "0  335104872099066692  positive   \n",
       "1  796528524030124618  positive   \n",
       "2  760964834217238632  positive   \n",
       "3  147713180324524046  negative   \n",
       "4  732302280474120023  negative   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  felt privileged to play foo fighters songs on ...  \n",
       "1   pakistan may be an islamic country, but der a...  \n",
       "2  happy birthday to the coolest golfer in bali! ...  \n",
       "3   tmills is going to tucson! but the 29th and i...  \n",
       "4  hmmmmm where are the #blacklivesmatter when ma...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase\n",
    "train_data['tweet_text'] = train_data['tweet_text'].str.lower()\n",
    "dev_data['tweet_text'] = dev_data['tweet_text'].str.lower()\n",
    "# Remove URLs. Note that URLs may appear in different forms\n",
    "train_data['tweet_text'] = train_data['tweet_text'].str.replace(r'(((https?:\\/\\/)|(w{3}.))[\\S]*)|([\\w\\d\\/\\.]*\\.(com|cn|co|net|org|edu|uk|int|js|html))', '')\n",
    "dev_data['tweet_text'] = dev_data['tweet_text'].str.replace(r'(((https?:\\/\\/)|(w{3}.))[\\S]*)|([\\w\\d\\/\\.]*\\.(com|cn|co|net|org|edu|uk|int|js|html))', '')\n",
    "# remove twitter handles\n",
    "train_data['tweet_text'] = train_data['tweet_text'].str.replace(r'\\@[\\S]*', '')\n",
    "dev_data['tweet_text'] = dev_data['tweet_text'].str.replace(r'\\@[\\S]*', '')\n",
    "# Remove numbers that are fully made of digits\n",
    "train_data['tweet_text'] = train_data['tweet_text'].str.replace(r'\\b\\d+\\b','')\n",
    "dev_data['tweet_text'] = dev_data['tweet_text'].str.replace(r'\\b\\d+\\b','')\n",
    "# Remove words with only 1 character. \n",
    "train_data['tweet_text'] = train_data['tweet_text'].str.replace(r'\\b\\w\\b','')\n",
    "dev_data['tweet_text'] = dev_data['tweet_text'].str.replace(r'\\b\\w\\b','')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF Vectorizer\n",
    "stopset = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stopset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment becomes dependent variable\n",
    "train_y = train_data.sentiment\n",
    "dev_y = dev_data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = vectorizer.fit_transform(train_data.tweet_text)\n",
    "dev_X = vectorizer.transform(dev_data.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45026,)\n",
      "(45026, 41885)\n",
      "(2000,)\n",
      "(2000, 41885)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(train_X.shape)\n",
    "print(dev_y.shape)\n",
    "print(dev_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655\n",
      "[[432  12 259]\n",
      " [ 38 152 188]\n",
      " [138  55 726]]\n"
     ]
    }
   ],
   "source": [
    "# train MaxEnt classifier (Logisitic regression)\n",
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "# test model accuracy\n",
    "pred_y_mxe = clf.predict(dev_X)\n",
    "acc_score_mxe = accuracy_score(dev_y, pred_y_mxe)\n",
    "conf_mat_mxe = confusion_matrix(dev_y, pred_y_mxe, labels = ['positive', 'negative', 'neutral'])\n",
    "\n",
    "print(acc_score_mxe)\n",
    "print(conf_mat_mxe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5975\n",
      "[[390   1 312]\n",
      " [ 43  41 294]\n",
      " [145  10 764]]\n"
     ]
    }
   ],
   "source": [
    "# train naive bayes classifier\n",
    "clf2 = naive_bayes.MultinomialNB()\n",
    "clf2.fit(train_X, train_y)\n",
    "\n",
    "# test model accuracy\n",
    "pred_y_nb = clf2.predict(dev_X)\n",
    "acc_score_nb = accuracy_score(dev_y, pred_y_nb)\n",
    "conf_mat_nb = confusion_matrix(dev_y, pred_y_nb, labels = ['positive', 'negative', 'neutral'])\n",
    "\n",
    "print(acc_score_nb)\n",
    "print(conf_mat_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train svm\n",
    "clf3 = linear_model.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "clf3.fit(train_X, train_y)\n",
    "\n",
    "# test model accuracy\n",
    "pred_y_svm = clf3.predict(dev_X)\n",
    "acc_score_svm = accuracy_score(dev_y, pred_y_svm)\n",
    "conf_mat_svm = confusion_matrix(dev_y, pred_y_svm, labels = ['positive', 'negative', 'neutral'])\n",
    "\n",
    "print(acc_score_svm)\n",
    "print(conf_mat_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
